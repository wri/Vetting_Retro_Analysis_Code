
## Prep Steps ##

install.packages("sf")
install.packages("tidyverse")
install.packages("tidycensus")
install.packages("tmap")
install.packages("data.table")
install.packages("base")
install.packages("snakecase")
install.packages("car")
install.packages("broom")
install.packages("rdrobust")
install.packages("estimatr")
install.packages("modelsummary")
install.packages("kableExtra")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("randomForest")


library(sf)
library(tidyverse)
library(tidycensus)
library(tmap)
library(data.table)
library(base)
library(snakecase)
library(car)
library(broom)
library(rdrobust)
library(estimatr)
library(modelsummary)
library(kableExtra)
library(rpart)
library(rpart.plot)
library(randomForest)


setwd("/Users/neilstein/Documents/Work/WRI/Research/TerraFund Vetting")
TF_Vetting <- read.csv("Applications-TF Landscapes Ratings Fields.csv", header = T)
HBF_Vetting <- read.csv("HBF_Vetting_Scores.csv", header = T)
LA_Vetting <- read.csv("LA24_Vetting_Scores.csv", header = T)

## First Round Analysis - Key Factors to Selection for TerraFund Landscapes ##

# converting selection to booleans
TF_Vetting$Project_Outcome <- ifelse(TF_Vetting$Final.Application.Decision == "Selected",1,0)

# dealing with NA values
TF_Vetting <- replace(TF_Vetting, is.na(TF_Vetting), 0)

# preparing exclusions
excluded_cols <- c( "Airtable.Application.ID", "Organization.Name.Clean..lookup.", "Project.Name", "Cohort", "Application.Type", "Final.Application.Decision", "Organization.Type..lookup.", "Project_Outcome")
lm_all <- TF_Vetting$Project_Outcome ~ .[ !names(.) %in% excluded_cols]

# filtering to streamline the review
filt_data <- TF_Vetting[, !names(TF_Vetting) %in% excluded_cols]

# first pass model -- looks good!

vetting_all_model <- lm(forumla = lm_all, data = filt_data)
summary(vetting_all_model)

# filtering results to find our strongest and weakest predictors
key_coefficients <- coef(vetting_all_model)
key_coefficient_names <- names(key_coefficients)

key_coefficient_data <- data.frame(coefficient = abs(key_coefficients), name = key_coefficient_names)

# sorting and slicing into top 15 and bottom 15
key_coefficient_data <- key_coefficient_data[order(key_coefficient_data$coefficient, decreasing = TRUE), ]

vetting_top_predictors <- key_coefficient_data[1:15, ]
vetting_bottom_predictors <- key_coefficient_data[(nrow(key_coefficient_data) - 14):nrow(key_coefficient_data), ]

print("Top 15 Strongest Predictors:")
print(vetting_top_predictors)

print("Bottom 15 Weakest Predictors:")
print(vetting_bottom_predictors)

write_csv(vetting_top_predictors, file = "vetting_top_predictors.csv")
write_csv(vetting_bottom_predictors, file = "vetting_bottom_predictors.csv")




## First Round Analysis - Key Factors to Selection for HBF Selection ##

# cleaning field titles
names(HBF_Vetting) <- to_snake_case(names(HBF_Vetting))

# converting selection to booleans
HBF_Vetting$Project_Outcome <- ifelse(HBF_Vetting$final_decision_for_rfp == "Pass to DD/Interview Stage",1,0)

# dealing with NA values
HBF_Vetting <- replace(HBF_Vetting, is.na(HBF_Vetting), 0)

# preparing exclusions
excluded_cols_HBF <- c("organisation_name", "project_id", "rfp_b_organization_type", "gen_rfp_first_reviewer_final_recommendation", "exp_rfp_second_reviewer_final_recommendation", "final_selection_decision_process_closing", "final_decision_for_rfp", "Project_Outcome")

# using this step only for Non-Profit analysis
FP_Only_cols_HBF <- c("gen_rfp_fp_rating_of_fpc_farmer_membership","exp_rfp_fp_rating_of_fpc_farmer_membership", "gen_rfp_fp_rating_of_fpc_support_entities", "exp_rfp_fp_rating_of_fpc_support_entities", "gen_rfp_fp_rating_of_fpc_bo_d_composition", "exp_rfp_fp_rating_of_fpc_bo_d_composition", "gen_rfp_fp_rating_of_fpc_management_involvement", "exp_rfp_fp_rating_of_fpc_management_involvement", "review_gen_rfp_fp_rating_of_projected_2023_2024_revenue", "review_exp_rfp_fp_rating_of_projected_2023_2024_revenue", "gen_rfp_fp_rating_of_income_generation_explanation", "exp_rfp_fp_rating_of_income_generation_explanation", "gen_rfp_fp_rating_of_loan_debt_response", "exp_rfp_fp_rating_of_loan_debt_response", "gen_rfp_fp_rating_of_financing_ask", "exp_rfp_fp_rating_of_financing_ask", "gen_rfp_fp_rating_of_proposed_use_of_funds", "exp_rfp_fp_rating_of_proposed_use_of_funds", "gen_rfp_rating_of_business_innovation", "exp_rfp_rating_of_business_innovation", "gen_rfp_rating_of_market_potential", "exp_rfp_rating_of_market_potential", "gen_rfp_rating_of_product_service_availability", "exp_rfp_rating_of_product_service_availability", "gen_rfp_rating_of_product_service_availability", "exp_rfp_rating_of_product_service_availability", "gen_rfp_rating_of_growth_envisioned_description", "exp_rfp_rating_of_growth_envisioned_description", "gen_rfp_rating_of_limitations_on_operational_growth", "exp_rfp_rating_of_limitations_on_operational_growth", "gen_rfp_rating_of_financial_stability_risks", "exp_rfp_rating_of_financial_stability_risks")

#additional filtering to focus on non-profit entities
HBF_filt_data_NP <- HBF_Vetting[HBF_Vetting$rfp_b_organization_type == "Non-Profit Organization", ]

# filtering to streamline the review, removing non-numerical and for-profit exclusive columns
HBF_filt_data_NP <- HBF_filt_data_NP[, !names(HBF_filt_data_NP) %in% excluded_cols_HBF]
HBF_filt_data_NP <- HBF_filt_data_NP[, !names(HBF_filt_data_NP) %in% FP_Only_cols_HBF]

lm_HBF_all <- HBF_filt_data_NP$Project_Outcome ~ .[ !names(.) %in% excluded_cols_HBF]

# first pass model -- looks good!

vetting_HBF_model <- lm(forumla = lm_HBF_all, data = HBF_filt_data_NP)
summary(vetting_HBF_model)

# filtering results to find our strongest and weakest predictors
HBF_key_coefficients <- coef(vetting_HBF_model)
HBF_key_coefficient_names <- names(HBF_key_coefficients)

HBF_key_coefficient_data <- data.frame(coefficient = abs(HBF_key_coefficients), name = HBF_key_coefficient_names)

# sorting and slicing into top 10 and bottom 10
HBF_key_coefficient_data <- HBF_key_coefficient_data[order(HBF_key_coefficient_data$coefficient, decreasing = TRUE), ]

HBF_vetting_top_predictors <- HBF_key_coefficient_data[1:15, ]
HBF_vetting_bottom_predictors <- HBF_key_coefficient_data[(nrow(HBF_key_coefficient_data) - 14):nrow(HBF_key_coefficient_data), ]

print("Top 15 Strongest Predictors:")
print(HBF_vetting_top_predictors)

print("Bottom 15 Weakest Predictors:")
print(HBF_vetting_bottom_predictors)

write_csv(HBF_vetting_top_predictors, file = "HBF_vetting_top_predictors.csv")
write_csv(HBF_vetting_bottom_predictors, file = "HBF_vetting_bottom_predictors.csv")



## First Round Analysis - Key Factors to Selection for LA24 Selection ##

# cleaning field titles
names(LA_Vetting) <- to_snake_case(names(LA_Vetting))

# converting selection to booleans
LA_Vetting$Project_Outcome <- ifelse(LA_Vetting$x_review_acceptance == "Accept",1,0)

# dealing with NA values
LA_Vetting <- replace(LA_Vetting, is.na(LA_Vetting), 0)

# preparing exclusions
excluded_cols_LA <- c("name_organisation", "x_terra_match_application_uuid", "x_review_acceptance", "x_wri_review_landscape_program_stage_recommendation", "x_review_mdf_landscape_program_stage_recommendation", "x_review_apf_landscape_program_stage_recommendation", "x_review_wi_landscape_program_stage_recommendation", "x_review_aaa_landscape_program_stage_recommendation","x_review_mkh_landscape_program_stage_recommendation")

# filtering to streamline the review, removing non-numerical and for-profit exclusive columns
LA_filt_data <- LA_Vetting[, !names(LA_Vetting) %in% excluded_cols_LA]

lm_LA_all <- LA_filt_data_NP$Project_Outcome ~ .[ !names(.) %in% excluded_cols_LA]

# first pass model -- looks good!

vetting_LA_model <- lm(forumla = lm_LA_all, data = LA_filt_data)
summary(vetting_LA_model)

# filtering results to find our strongest and weakest predictors
LA_key_coefficients <- coef(vetting_LA_model)
LA_key_coefficient_names <- names(LA_key_coefficients)

LA_key_coefficient_data <- data.frame(coefficient = abs(LA_key_coefficients), name = LA_key_coefficient_names)

# sorting and slicing into top 15 and bottom 15
LA_key_coefficient_data <- LA_key_coefficient_data[order(LA_key_coefficient_data$coefficient, decreasing = TRUE), ]

LA_vetting_top_predictors <- LA_key_coefficient_data[1:15, ]
LA_vetting_bottom_predictors <- LA_key_coefficient_data[(nrow(LA_key_coefficient_data) - 14):nrow(LA_key_coefficient_data), ]

print("Top 15 Strongest Predictors:")
print(LA_vetting_top_predictors)

print("Bottom 15 Weakest Predictors:")
print(LA_vetting_bottom_predictors)

write_csv(LA_vetting_top_predictors, file = "LA_vetting_top_predictors.csv")
write_csv(LA_vetting_bottom_predictors, file = "LA_vetting_bottom_predictors.csv")






## Second Major Analysis -- Fuzzy RDD on our selected applicants ##
# TerraFund Landscapes #
TF_RDD <- read.csv("Applications-TF Landscapes Ratings Fields.csv", header = T)
names(TF_RDD) <- to_snake_case(names(TF_RDD))
TF_RDD <- replace(TF_RDD, is.na(TF_RDD), 0)
TF_RDD$project_outcome <- ifelse(TF_RDD$final_application_decision == "Selected",1,0)
View(TF_RDD)

# focusing on on numeric columns only
TF_excluded_cols <- c( "airtable_application_id", "organization_name_clean_lookup", "project_name", "cohort", "application_type", "final_application_decision", "organization_type_lookup")
TF_numeric_cols <- sapply(TF_RDD, is.numeric)

# due to scoring inconsistencies in the for-profit side I will be removing their applications
TF_RDD <- TF_RDD[TF_RDD$organization_type_lookup == "Non-Profit Organization", ]

# calculating an average 'GPA' in order to create a baseline spectrum
TF_RDD <- TF_RDD %>%
  mutate(average = rowMeans(TF_RDD[, TF_numeric_cols], na.rm = TRUE))
  

# creating groupings to explore the 'fuzziness' of the RDD
# first, need to collect the column titles
TF_RDD_all_cols <- names(TF_RDD)
TF_RDD_col_titles <- TF_RDD_all_cols[!TF_RDD_all_cols %in% TF_excluded_cols]
write.csv(TF_RDD_col_titles, file = "TF_landscapes_titles.csv", row.names = FALSE, quote = FALSE)

#the thematic groupings were created offline and are available in the guidance document on Sharepoint
TFL_themes <- read.csv("tfl_themes.csv")
names(TFL_themes) <- to_snake_case(names(TFL_themes))


# initial attempts to insert the themes automatically failed, hardcoding all themes:
org_mgmt <- c("letters_of_reference_grade", "expert_letters_of_reference_grade", "organization_description_mission_grade", "expert_organization_description_grade", "organizational_composition_rating", "expert_organizational_composition_rating", "historic_funding_streams_rating", "expert_historic_funding_streams_rating", "historic_financial_strength_rating", "expert_historic_financial_strength_rating","historic_working_photos_rating", "expert_monitoring_photos_rating")

org_hist <- c("hectares_restored_historically_rating", "expert_hectares_restored_historically_rating", "historic_tree_survival_rate_rating", "expert_historic_tree_survival_rate_rating", "trees_species_grown_historically_rating", "expert_trees_species_grown_historically_rating", "trees_restored_historically_rating", "expert_trees_restored_historically_rating", "geography_of_historic_work_rating", "expert_geography_of_historic_work_rating", "proposed_historic_land_tenure_rating", "expert_proposed_historic_land_tenure_rating", "historic_community_engagement_rating", "expert_historic_community_engagement_rating")

prop_plan <- c("tree_maintenance_plan_rating", "expert_tree_maintenance_plan_rating", "proposed_project_objectives_rating", "expert_proposed_project_objectives_rating", "project_timeline_rating", "expert_project_timeline_rating", "historic_monitoring_experience_rating", "expert_historic_monitoring_experience_rating", "risk_mitigation_rating", "expert_risk_mitigation_rating")

prop_enviro <- c("proposed_boundary_rating", "expert_proposed_boundary_rating", "proposed_monitoring_and_maintenance_plan_rating", "expert_proposed_monitoring_and_maintenance_plan_rating", "rating_of_hectares_to_be_restored", "expert_rating_of_hectares_to_be_restored", "restoration_interventions_planned_rating", "expert_restoration_interventions_planned_rating", "proposed_species_of_trees_rating", "expert_proposed_species_of_trees_rating", "rating_of_trees_to_be_restored", "expert_rating_of_trees_to_be_restored", "rating_of_local_landscapes_assessment", "expert_rating_of_local_landscapes_assessment", "nursery_approach_rating", "expert_nursery_approach_rating", "environmental_goals_rating", "expert_environmental_goals_rating", "proposed_water_impact_rating", "expert_proposed_water_impact_rating")

prop_social <- c("rating_of_project_beneficiaries", "expert_rating_of_project_beneficiaries", "proposed_partner_rating", "expert_proposed_partner_rating", "proposed_socio_economic_impact_rating", "expert_proposed_socio_economic_impact_rating", "rating_of_jobs_to_be_created", "expert_rating_of_jobs_to_be_created", "livelihood_degradation_impacts_rating", "expert_livelihood_degradation_impacts_rating", "proposed_food_impact_rating", "expert_proposed_food_impact_rating")

# score by grouping
TF_RDD <- TF_RDD %>%
  mutate(org_mgmt_avg = rowMeans(select(., all_of(org_mgmt)), na.rm = TRUE))

TF_RDD <- TF_RDD %>%
  mutate(org_hist_avg = rowMeans(select(., all_of(org_hist)), na.rm = TRUE))

TF_RDD <- TF_RDD %>%
  mutate(prop_plan_avg = rowMeans(select(., all_of(prop_plan)), na.rm = TRUE))
  
TF_RDD <- TF_RDD %>%
  mutate(prop_enviro_avg = rowMeans(select(., all_of(prop_enviro)), na.rm = TRUE))
  
TF_RDD <- TF_RDD %>%
  mutate(prop_social_avg = rowMeans(select(., all_of(prop_social)), na.rm = TRUE))
  
  

# Testing our data -- decision tree model 
TF_tree_model <- rpart(TF_RDD$final_application_decision ~ ., data = TF_RDD)
rpart.plot(TF_tree_model)

# pruning the tree model
TF_pruned_model <- prune(TF_tree_model, cp = 0.1)
rpart.plot(TF_pruned_model)

# random forest modeling, another test to see our data better

TF_rf_model <- randomForest(TF_RDD$final_application_decision ~ ., data = TF_RDD)
importance(TF_rf_model)


# for loop to build out our models

for (theme in TFL_themes$thematic_area) {
  theme_cols <- TFL_themes[TFL_themes$thematic_area == theme, "fields_involved"]
  theme_cols <- unlist(strsplit(theme_cols, ",")) %>% str_trim() %>% str_squish()
  
  # Debug: Print theme and columns involved
  cat("\nTheme:", theme, "\n")
  cat("Theme Columns:", theme_cols, "\n")
  
  valid_cols <- intersect(theme_cols, names(TF_RDD))
  
  # Debug: Print valid columns
  cat("Valid Columns:", valid_cols, "\n")
  
  if (length(valid_cols) > 0) {
    # Ensure the data is subset correctly and remove rows with missing values
    theme_data <- TF_RDD[, c(valid_cols, "project_outcome"), drop = FALSE]  # Use drop = FALSE to avoid dropping dimensions
    theme_data <- na.omit(theme_data)
    
    # Convert project_outcome to a factor if it's not already
    theme_data$project_outcome <- as.factor(theme_data$project_outcome)
    
    project_outcome <- "project_outcome"
    
    # Prepare the predictors and outcome for rdrobust
    X <- theme_data[, valid_cols, drop = FALSE]
    Y <- theme_data[[project_outcome]]
    
    # Call the rdrobust function
    model <- tryCatch({
      rdrobust(X, Y, fuzzy = TRUE)
    }, error = function(e) {
      cat("Error in rdrobust for theme:", theme, "\n", conditionMessage(e), "\n")
      NULL
    })
    
    if (!is.null(model)) {
      print(model)
    } else {
      cat("No valid model results for theme:", theme, "\n")
    }
    cat("Results for theme:", theme, "\n")
  } else {
    cat("No valid columns for theme:", theme, "\n")
  }
}


# improved approach

for (theme in TFL_themes$thematic_area) {
  theme_cols <- TFL_themes[TFL_themes$thematic_area == theme, "fields_involved"]
  theme_cols <- unlist(strsplit(theme_cols, ",")) %>% str_trim() %>% str_squish()

  # Debug: Print theme and columns involved
  cat("\nTheme:", theme, "\n")
  cat("Theme Columns:", theme_cols, "\n")

  valid_cols <- intersect(theme_cols, names(TF_RDD))

  # Debug: Print valid columns
  cat("Valid Columns:", valid_cols, "\n")

  if (length(valid_cols) > 0) {
    # Ensure the data is subset correctly and remove rows with missing values
    theme_data <- TF_RDD[, c(valid_cols, "project_outcome"), drop = FALSE]
    theme_data <- na.omit(theme_data)

    # Convert project_outcome to a factor if it's not already
    theme_data$project_outcome <- as.factor(theme_data$project_outcome)

    project_outcome <- "project_outcome"

    # Prepare the predictors and outcome for rdrobust
    X <- theme_data[, valid_cols, drop = FALSE]
    Y <- theme_data[[project_outcome]]

    # Check data types and dimensions
    print(str(X))
    print(str(Y))

    # Call the rdrobust function with debugging
    model <- tryCatch({
      browser()  # Add breakpoint for interactive debugging
      rdrobust(X, Y, fuzzy = TRUE)
    }, error = function(e) {
      cat("Error in rdrobust for theme:", theme, "\n", conditionMessage(e), "\n")
      NULL
    })

    if (!is.null(model)) {
      print(model)
    } else {
      cat("No valid model results for theme:", theme, "\n")
    }
    cat("Results for theme:", theme, "\n")
  } else {
    cat("No valid columns for theme:", theme, "\n")
  }
}


